{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded successfully.\n",
      "Preprocessing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17034\\AppData\\Local\\Temp\\ipykernel_28540\\3058739453.py:35: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  df = df.interpolate(method='time')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['Market_Return', 'VIX_MA_10', 'Market_Volatility', 'VIX', 'Price_Range_Pct', 'Volatility_60d', 'Lower_Channel_50', 'Volatility_20d', 'Lower_Channel_20', 'Channel_Width_50', 'Upper_Channel_20', 'Volatility_5d', 'Channel_Width_20', 'Upper_Channel_50', 'BB_Width_20']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout, BatchNormalization, Multiply, Flatten, Activation, RepeatVector, Permute\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# --- Data Loading and Preprocessing ---\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv('sp500_master_data.csv', parse_dates=['Date'], index_col='Date')\n",
    "print(\"Data loaded successfully.\")\n",
    "\n",
    "print(\"Preprocessing data...\")\n",
    "# Calculate Returns\n",
    "df['Returns'] = df['Close'].pct_change()\n",
    "\n",
    "# Handle missing values with time-based interpolation\n",
    "df = df.interpolate(method='time')\n",
    "df = df.dropna()\n",
    "\n",
    "# Create target variable: 0 (Down), 1 (Neutral), 2 (Up)\n",
    "price_change_threshold = 0.005\n",
    "df['target'] = np.where(df['Returns'].shift(-1) > price_change_threshold, 2,\n",
    "                        np.where(df['Returns'].shift(-1) < -price_change_threshold, 0, 1))\n",
    "df = df.dropna(subset=['target'])\n",
    "df['target'] = df['target'].astype(int)\n",
    "\n",
    "# --- Feature Selection using Mutual Information ---\n",
    "# Select numerical features for MI calculation\n",
    "features = df.select_dtypes(include=[np.number]).columns.drop('target')\n",
    "mi_scores = mutual_info_classif(df[features], df['target'], random_state=42)\n",
    "mi_df = pd.DataFrame({'Feature': features, 'MI Score': mi_scores}).sort_values('MI Score', ascending=False)\n",
    "selected_features = mi_df.head(15)['Feature'].tolist()  # Top 15 features\n",
    "print(f\"Selected features: {selected_features}\")\n",
    "\n",
    "# --- Normalize Features ---\n",
    "scaler = MinMaxScaler()\n",
    "df[selected_features] = scaler.fit_transform(df[selected_features])\n",
    "\n",
    "# --- Prepare Sequence Data ---\n",
    "sequence_length = 30\n",
    "X, y = [], []\n",
    "for i in range(len(df) - sequence_length):\n",
    "    X.append(df[selected_features].iloc[i:i+sequence_length].values)\n",
    "    y.append(df['target'].iloc[i+sequence_length])\n",
    "X = np.array(X)\n",
    "y = tf.keras.utils.to_categorical(np.array(y), num_classes=3)\n",
    "\n",
    "# --- Time Series Split ---\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for train_idx, test_idx in tscv.split(X):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    break  # Use the last split for training and testing\n",
    "\n",
    "# --- Build CNN-BiLSTM Model with Attention ---\n",
    "def attention_layer(inputs):\n",
    "    weights = Dense(1, activation='tanh')(inputs)\n",
    "    weights = Flatten()(weights)\n",
    "    weights = Activation('softmax')(weights)\n",
    "    weights = RepeatVector(inputs.shape[2])(weights)\n",
    "    weights = Permute([2, 1])(weights)\n",
    "    output = Multiply()([inputs, weights])\n",
    "    return tf.keras.layers.Lambda(lambda x: tf.keras.backend.sum(x, axis=1))(output)\n",
    "\n",
    "def build_model(input_shape, num_classes=3):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(64, 3, padding='same', activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Conv1D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Bidirectional(LSTM(32, return_sequences=True))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = attention_layer(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Train Model ---\n",
    "model = build_model((sequence_length, len(selected_features)))\n",
    "y_train_labels = np.argmax(y_train, axis=1)\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_labels), y=y_train_labels)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "               ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)]\n",
    ")\n",
    "\n",
    "# --- Evaluate Model ---\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Down', 'Neutral', 'Up']))\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Down', 'Neutral', 'Up'], yticklabels=['Down', 'Neutral', 'Up'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Workflow completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
