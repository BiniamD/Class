{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing train: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\n",
      "Error processing test: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\n",
      "\n",
      "Aggregate Performance Metrics:\n",
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from typing import Tuple, Dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Flatten, Dropout # type: ignore # type: ignore\n",
    "from typing import Dict\n",
    "\n",
    "#ingor warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class ChartPatternDetector:\n",
    "    \"\"\"CNN model for detecting chart patterns (H1)\"\"\"\n",
    "    def __init__(self, sequence_length: int):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.model = self._build_cnn()\n",
    "        \n",
    "    def _build_cnn(self) -> Sequential:\n",
    "        model = Sequential([\n",
    "            Conv1D(32, 3, activation='relu', input_shape=(self.sequence_length, 1)),\n",
    "            MaxPooling1D(2),\n",
    "            Conv1D(64, 3, activation='relu'),\n",
    "            MaxPooling1D(2),\n",
    "            Conv1D(64, 3, activation='relu'),\n",
    "            Flatten(),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(4, activation='softmax')  # head&shoulders, double top/bottom, no pattern\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def train(self, X_train: np.ndarray, y_train: np.ndarray, epochs: int = 10, batch_size: int = 32):\n",
    "        \"\"\"Train the CNN model\"\"\"\n",
    "        self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "    \n",
    "    def prepare_pattern_data(self, prices: np.array) -> np.array:\n",
    "        \"\"\"Prepare data for pattern detection\"\"\"\n",
    "        windows = []\n",
    "        for i in range(len(prices) - self.sequence_length):\n",
    "            window = prices[i:(i + self.sequence_length)]\n",
    "            normalized_window = (window - window.min()) / (window.max() - window.min())\n",
    "            windows.append(normalized_window)\n",
    "        return np.array(windows)\n",
    "    \n",
    "    def evaluate_patterns(self, y_true, y_pred) -> Dict:\n",
    "        \"\"\"Calculate pattern recognition metrics\"\"\"\n",
    "        return {\n",
    "            'accuracy': accuracy_score(y_true.argmax(axis=1), y_pred.argmax(axis=1)),\n",
    "            'precision': precision_score(y_true.argmax(axis=1), y_pred.argmax(axis=1), average='weighted'),\n",
    "            'recall': recall_score(y_true.argmax(axis=1), y_pred.argmax(axis=1), average='weighted'),\n",
    "            'f1': f1_score(y_true.argmax(axis=1), y_pred.argmax(axis=1), average='weighted')\n",
    "        }\n",
    "\n",
    "class PricePredictor:\n",
    "    \"\"\"RNN model for price prediction compared to traditional methods (H2)\"\"\"\n",
    "    def __init__(self, sequence_length: int, n_features: int):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.n_features = n_features\n",
    "        self.rnn_model = self._build_rnn()\n",
    "        \n",
    "    def _build_rnn(self) -> Sequential:\n",
    "        model = Sequential([\n",
    "            LSTM(100, return_sequences=True, input_shape=(self.sequence_length, self.n_features)),\n",
    "            Dropout(0.2),\n",
    "            LSTM(100, return_sequences=False),\n",
    "            Dropout(0.2),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        return model\n",
    "    \n",
    "    def moving_average_strategy(self, prices: pd.Series, short_window=20, long_window=50) -> pd.Series:\n",
    "        \"\"\"Traditional moving average crossover strategy\"\"\"\n",
    "        short_ma = prices.rolling(window=short_window).mean()\n",
    "        long_ma = prices.rolling(window=long_window).mean()\n",
    "        signals = pd.Series(0, index=prices.index)\n",
    "        signals[short_ma > long_ma] = 1  # Buy signal\n",
    "        signals[short_ma < long_ma] = -1  # Sell signal\n",
    "        return signals\n",
    "\n",
    "    def compare_performance(self, rnn_predictions: np.array, ma_signals: pd.Series, \n",
    "                          actual_returns: pd.Series) -> Dict:\n",
    "        \"\"\"Compare RNN vs Moving Average performance\"\"\"\n",
    "        rnn_returns = pd.Series(rnn_predictions).pct_change()\n",
    "        ma_returns = ma_signals.shift(1) * actual_returns\n",
    "        \n",
    "        return {\n",
    "            'rnn_sharpe': self.calculate_sharpe_ratio(rnn_returns),\n",
    "            'ma_sharpe': self.calculate_sharpe_ratio(ma_returns),\n",
    "            'rnn_max_drawdown': self.calculate_max_drawdown(rnn_returns),\n",
    "            'ma_max_drawdown': self.calculate_max_drawdown(ma_returns)\n",
    "        }\n",
    "\n",
    "class TradingSystem:\n",
    "    \"\"\"Combined trading system using multiple indicators (H3)\"\"\"\n",
    "    def __init__(self, pattern_detector: ChartPatternDetector, price_predictor: PricePredictor):\n",
    "        self.pattern_detector = pattern_detector\n",
    "        self.price_predictor = price_predictor\n",
    "        \n",
    "    def generate_signals(self, data: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"Generate trading signals combining all indicators\"\"\"\n",
    "        pattern_signals = self.pattern_detector.predict(data['Close'].values)\n",
    "        price_predictions = self.price_predictor.predict(data)\n",
    "        technical_signals = self.analyze_technical_indicators(data)\n",
    "        \n",
    "        # Combine signals using weighted approach\n",
    "        combined_signals = (\n",
    "            0.4 * pattern_signals +\n",
    "            0.4 * np.sign(price_predictions - data['Close'].values) +\n",
    "            0.2 * technical_signals\n",
    "        )\n",
    "        \n",
    "        return pd.Series(combined_signals, index=data.index)\n",
    "    \n",
    "    def analyze_technical_indicators(self, data: pd.DataFrame) -> np.array:\n",
    "        \"\"\"Analyze technical indicators for signal generation\"\"\"\n",
    "        signals = np.zeros(len(data))\n",
    "        \n",
    "        # RSI signals\n",
    "        signals[data['RSI'] < 30] += 1  # Oversold\n",
    "        signals[data['RSI'] > 70] -= 1  # Overbought\n",
    "        \n",
    "        # MACD signals\n",
    "        signals[data['MACD'] > data['Signal_Line']] += 1\n",
    "        signals[data['MACD'] < data['Signal_Line']] -= 1\n",
    "        \n",
    "        # Bollinger Bands signals\n",
    "        signals[data['Close'] < data['Lower_Band']] += 1\n",
    "        signals[data['Close'] > data['Upper_Band']] -= 1\n",
    "        \n",
    "        return signals\n",
    "    \n",
    "    def calculate_performance_metrics(self, signals: pd.Series, \n",
    "                                   returns: pd.Series) -> Dict:\n",
    "        \"\"\"Calculate trading performance metrics\"\"\"\n",
    "        strategy_returns = signals.shift(1) * returns\n",
    "        \n",
    "        return {\n",
    "            'sharpe_ratio': self.calculate_sharpe_ratio(strategy_returns),\n",
    "            'max_drawdown': self.calculate_max_drawdown(strategy_returns),\n",
    "            'total_return': (1 + strategy_returns).prod() - 1,\n",
    "            'annualized_return': (1 + strategy_returns).prod() ** (252/len(returns)) - 1\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_sharpe_ratio(returns: pd.Series, risk_free_rate=0.02) -> float:\n",
    "        \"\"\"Calculate Sharpe Ratio\"\"\"\n",
    "        excess_returns = returns - risk_free_rate/252\n",
    "        return np.sqrt(252) * excess_returns.mean() / returns.std()\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_max_drawdown(returns: pd.Series) -> float:\n",
    "        \"\"\"Calculate Maximum Drawdown\"\"\"\n",
    "        cumulative = (1 + returns).cumprod()\n",
    "        running_max = cumulative.expanding().max()\n",
    "        drawdowns = cumulative / running_max - 1\n",
    "        return drawdowns.min()\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, data_path: str):\n",
    "        self.data_path = data_path\n",
    "        self.scaler = MinMaxScaler()\n",
    "        \n",
    "    def load_and_prepare_data(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        # Load master data\n",
    "        df = pd.read_csv(self.data_path)\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        \n",
    "        # Sort by date\n",
    "        df = df.sort_values('Date')\n",
    "        \n",
    "        # Prepare features\n",
    "        feature_columns = ['Close', 'Volume', 'RSI', 'MACD', 'Signal_Line', \n",
    "                         'Upper_Band', 'Lower_Band', 'Returns', 'Volatility', 'Volume_Ratio']\n",
    "        \n",
    "        # Scale features\n",
    "        scaled_data = self.scaler.fit_transform(df[feature_columns])\n",
    "        \n",
    "        # Prepare sequences\n",
    "        X, y = self._prepare_sequences(scaled_data)\n",
    "        \n",
    "        # Split into train/test\n",
    "        split_idx = int(len(X) * 0.8)\n",
    "        X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "        y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "        \n",
    "        return {'train': X_train, 'test': X_test}, {'train': y_train, 'test': y_test}\n",
    "    \n",
    "    def _prepare_sequences(self, data: np.ndarray, sequence_length: int = 60) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - sequence_length):\n",
    "            X.append(data[i:(i + sequence_length)])\n",
    "            y.append(data[i + sequence_length, 0])\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "def main():\n",
    "    # Initialize data loader\n",
    "    data_loader = DataLoader('stock_data/sp500_master_data.csv')\n",
    "    X_dict, y_dict = data_loader.load_and_prepare_data()\n",
    "    \n",
    "    # Initialize models from previous implementation\n",
    "    pattern_detector = ChartPatternDetector(sequence_length=60)\n",
    "    price_predictor = PricePredictor(sequence_length=60, n_features=10)\n",
    "    trading_system = TradingSystem(pattern_detector, price_predictor)\n",
    "    \n",
    "    # Dictionary to store results\n",
    "    results = {}\n",
    "    \n",
    "    # Process each stock\n",
    "    for symbol in X_dict.keys():\n",
    "        try:\n",
    "            # Train models\n",
    "            pattern_detector.train(X_dict[symbol]['train'], y_dict[symbol]['train'])\n",
    "            price_predictor.train(X_dict[symbol]['train'], y_dict[symbol]['train'])\n",
    "            \n",
    "            # Generate predictions\n",
    "            signals = trading_system.generate_signals(X_dict[symbol]['test'])\n",
    "            \n",
    "            # Calculate performance metrics\n",
    "            performance = trading_system.calculate_performance_metrics(\n",
    "                signals, y_dict[symbol]['test']\n",
    "            )\n",
    "            \n",
    "            results[symbol] = performance\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {symbol}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Save results\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    results_df.to_csv('stock_data/trading_results.csv')\n",
    "    \n",
    "    # Calculate and display aggregate metrics\n",
    "    print(\"\\nAggregate Performance Metrics:\")\n",
    "    print(results_df.mean())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
